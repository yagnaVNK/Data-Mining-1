{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import  summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labmap = {0: \"n02089078-black-and-tan_coonhound\",\n",
    "          1: \"n02091831-Saluki\",\n",
    "          2: \"n02092002-Scottish_deerhound\",\n",
    "          3: \"n02095314-wire-haired_fox_terrier\"}\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.images = self.load_images()\n",
    "\n",
    "    def load_images(self):\n",
    "        images = []\n",
    "        for class_name in self.classes:\n",
    "            class_path = os.path.join(self.root_dir, class_name)\n",
    "            for filename in os.listdir(class_path):\n",
    "                image_path = os.path.join(class_path, filename)\n",
    "                images.append((image_path, self.class_to_idx[class_name]))\n",
    "        return images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.images[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "root_folder = '../DataSet/ProcessedDatasets/'\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "dog_dataset = CustomDataset(root_folder, transform=transform)\n",
    "\n",
    "batch_size = 16\n",
    "data_loader = DataLoader(dog_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load the pre-trained ResNet-18 model\n",
    "resnet_model = resnet18(pretrained=True)\n",
    "# Remove the final fully connected layer\n",
    "resnet_model = torch.nn.Sequential(*(list(resnet_model.children())[:-1]))\n",
    "resnet_model = resnet_model.to('cuda')\n",
    "# Set the model to evaluation mode\n",
    "resnet_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary(resnet_model,(3,224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "data_loader = DataLoader(dog_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Extract features using the pre-trained ResNet-18 model\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in data_loader:\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        features = resnet_model(images)\n",
    "        all_features.append(features.cpu().squeeze().numpy())\n",
    "        all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "# Concatenate features and labels\n",
    "all_features = np.concatenate(all_features, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents_dog = pca.fit_transform(all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans, SpectralClustering, Birch\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (a) K-means clustering\n",
    "kmeans = KMeans(n_clusters=4, init='random')\n",
    "kmeans_labels = kmeans.fit_predict(principalComponents_dog)\n",
    "\n",
    "# (b) KMeans with init='k-means++'\n",
    "kmeans_pp = KMeans(n_clusters=4, init='k-means++')\n",
    "kmeans_pp_labels = kmeans_pp.fit_predict(principalComponents_dog)\n",
    "\n",
    "# (c) Bisecting K-means\n",
    "bisecting_kmeans = Birch(n_clusters=4, threshold=0.01, branching_factor=50)\n",
    "bisecting_kmeans_labels = bisecting_kmeans.fit_predict(principalComponents_dog)\n",
    "\n",
    "# (d) Spectral clustering\n",
    "spectral_clustering = SpectralClustering(n_clusters=4)\n",
    "spectral_labels = spectral_clustering.fit_predict(principalComponents_dog)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot K-means clustering\n",
    "plt.subplot(221)\n",
    "plt.scatter(principalComponents_dog[:, 0], principalComponents_dog[:, 1], c=kmeans_labels, cmap='viridis')\n",
    "plt.title('K-means Clustering')\n",
    "\n",
    "# Plot KMeans with init='k-means++'\n",
    "plt.subplot(222)\n",
    "plt.scatter(principalComponents_dog[:, 0], principalComponents_dog[:, 1], c=kmeans_pp_labels, cmap='viridis')\n",
    "plt.title('KMeans with init=\\'k-means++\\'')\n",
    "\n",
    "# Plot Bisecting K-means\n",
    "plt.subplot(223)\n",
    "plt.scatter(principalComponents_dog[:, 0], principalComponents_dog[:, 1], c=bisecting_kmeans_labels, cmap='viridis')\n",
    "plt.title('Bisecting K-means')\n",
    "\n",
    "# Plot Spectral clustering\n",
    "plt.subplot(224)\n",
    "plt.scatter(principalComponents_dog[:, 0], principalComponents_dog[:, 1], c=spectral_labels, cmap='viridis')\n",
    "plt.title('Spectral Clustering')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import fowlkes_mallows_score, silhouette_score\n",
    "\n",
    "# (e) DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_labels = dbscan.fit_predict(principalComponents_dog)\n",
    "\n",
    "# (f) Agglomerative clustering\n",
    "# (f) Single link (MIN)\n",
    "single_link = AgglomerativeClustering(n_clusters=4, linkage='single')\n",
    "single_link_labels = single_link.fit_predict(principalComponents_dog)\n",
    "\n",
    "# (g) Complete link (MAX)\n",
    "complete_link = AgglomerativeClustering(n_clusters=4, linkage='complete')\n",
    "complete_link_labels = complete_link.fit_predict(principalComponents_dog)\n",
    "\n",
    "# (h) Group Average\n",
    "group_average = AgglomerativeClustering(n_clusters=4, linkage='average')\n",
    "group_average_labels = group_average.fit_predict(principalComponents_dog)\n",
    "\n",
    "# (i) Ward's method\n",
    "ward = AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "ward_labels = ward.fit_predict(principalComponents_dog)\n",
    "\n",
    "# Clustering evaluation metrics\n",
    "def evaluate_clustering(labels, true_labels):\n",
    "    fowlkes_mallows = fowlkes_mallows_score(true_labels, labels)\n",
    "    silhouette = silhouette_score(principalComponents_dog, labels)\n",
    "    return fowlkes_mallows, silhouette\n",
    "\n",
    "# Ground truth labels (assuming you have them)\n",
    "true_labels = all_labels\n",
    "\n",
    "# Evaluate DBSCAN\n",
    "dbscan_scores = evaluate_clustering(dbscan_labels, true_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate Agglomerative clustering methods\n",
    "single_link_scores = evaluate_clustering(single_link_labels, true_labels)\n",
    "complete_link_scores = evaluate_clustering(complete_link_labels, true_labels)\n",
    "group_average_scores = evaluate_clustering(group_average_labels, true_labels)\n",
    "ward_scores = evaluate_clustering(ward_labels, true_labels)\n",
    "\n",
    "# Print the evaluation scores\n",
    "print(\"DBSCAN Scores (Fowlkes-Mallows, Silhouette):\", dbscan_scores)\n",
    "print(\"Single Link Scores (Fowlkes-Mallows, Silhouette):\", single_link_scores)\n",
    "print(\"Complete Link Scores (Fowlkes-Mallows, Silhouette):\", complete_link_scores)\n",
    "print(\"Group Average Scores (Fowlkes-Mallows, Silhouette):\", group_average_scores)\n",
    "print(\"Ward Scores (Fowlkes-Mallows, Silhouette):\", ward_scores)\n",
    "\n",
    "# Rank methods based on Fowlkes-Mallows index\n",
    "methods_fm_rank = sorted([(dbscan_scores[0], 'DBSCAN'),\n",
    "                          (single_link_scores[0], 'Single Link'),\n",
    "                          (complete_link_scores[0], 'Complete Link'),\n",
    "                          (group_average_scores[0], 'Group Average'),\n",
    "                          (ward_scores[0], \"Ward's Method\")], reverse=True)\n",
    "\n",
    "# Rank methods based on Silhouette Coefficient\n",
    "methods_silhouette_rank = sorted([(dbscan_scores[1], 'DBSCAN'),\n",
    "                                 (single_link_scores[1], 'Single Link'),\n",
    "                                 (complete_link_scores[1], 'Complete Link'),\n",
    "                                 (group_average_scores[1], 'Group Average'),\n",
    "                                 (ward_scores[1], \"Ward's Method\")], reverse=True)\n",
    "\n",
    "# Print the rankings\n",
    "print(\"\\nRankings based on Fowlkes-Mallows Index:\")\n",
    "for rank, method in enumerate(methods_fm_rank, 1):\n",
    "    print(f\"{rank}. {method[1]}\")\n",
    "\n",
    "print(\"\\nRankings based on Silhouette Coefficient:\")\n",
    "for rank, method in enumerate(methods_silhouette_rank, 1):\n",
    "    print(f\"{rank}. {method[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
